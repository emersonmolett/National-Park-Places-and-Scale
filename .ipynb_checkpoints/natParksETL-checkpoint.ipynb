{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies and setup\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'admin'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-69a1d994621c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msqlalchemy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msqlalchemy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_engine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInteger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mString\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFloat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0madmin\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpassword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatabase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# from TAconfig import (user, password, host, port, database)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'admin'"
     ]
    }
   ],
   "source": [
    "# Python SQL toolkit and Object Relational Mapper\n",
    "import sqlalchemy\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import create_engine, inspect, func, desc, Column, Integer, String, Float\n",
    "# from admin import (user, password, host, port, database)\n",
    "\n",
    "# from TAconfig import (user, password, host, port, database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Extract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### A. &nbsp;National Parks (from JSON)\n",
    "- National Parks with correct lat/lng coordinates.\n",
    "- Incomplete dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data source URL and variable\n",
    "aURL = \"https://github.com/learn-chef/national-parks-java/blob/master/national-parks.json\"\n",
    "aFilePath = \"data/natParks.json\"\n",
    "print(f\"{aFilePath} is {round(os.path.getsize(aFilePath)/1024/1024, 2)} megabytes (MB).\\nMore info here:\\n{aURL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read JSON file into DataFrame\n",
    "a_df = pd.read_json(aFilePath)\n",
    "a_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. &nbsp;National Parks (from CSV)\n",
    "- All National Parks.\n",
    "- Complete dataset of National Park names, but missing 102 lat/lng coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data source URL and variable\n",
    "bURL = \"https://public-nps.opendata.arcgis.com/datasets/nps-boundary-1/data?geometry=79.963%2C-20.479%2C-104.959%2C70.899\"\n",
    "bFilePath = \"data/natParks.csv\"\n",
    "print(f\"{bFilePath} is {round(os.path.getsize(bFilePath)/1024/1024, 2)} megabytes (MB).\\nMore info here:\\n{bURL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV file into DataFrame\n",
    "bRaw_df = pd.read_csv(bFilePath)\n",
    "bRaw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. &nbsp;National Parks with Size/Area (from CSV)\n",
    "- All National Parks; complete dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data source URL and variable\n",
    "cURL = \"https://public-nps.opendata.arcgis.com/datasets/nps-boundary-1/data?geometry=79.963%2C-20.479%2C-104.959%2C70.899\"\n",
    "cFilePath = \"data/natParksArea.csv\"\n",
    "print(f\"{cFilePath} is {round(os.path.getsize(cFilePath)/1024/1024, 2)} megabytes (MB).\\nMore info here:\\n{cURL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV file into DataFrame\n",
    "cRaw_df = pd.read_csv(cFilePath)\n",
    "cRaw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Points of Interest\n",
    "- All Points of Interest within each National Park with lat/lng coordinates.\n",
    "- Complete dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data source URL and variable\n",
    "rawPointsURL = \"https://public-nps.opendata.arcgis.com/datasets/nps-points-of-interest-pois-geographic-coordinate-system-1?geometry=79.973%2C-21.130%2C-104.949%2C70.669\"\n",
    "rawPointsFilePath = \"data/pointsInterest.csv\"\n",
    "print(f\"{rawPointsFilePath} is {round(os.path.getsize(rawPointsFilePath)/1024/1024, 2)} megabytes (MB).\\nMore info here:\\n{rawPointsURL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV file into DataFrame\n",
    "rawPoints_df = pd.read_csv(rawPointsFilePath, low_memory = False)\n",
    "rawPoints_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attendance/Visitors (Recreation Visits)\n",
    "- Dataset does not include attendance numbers for trails and other unstaffed National Park locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data source URL and variable\n",
    "attendanceURL = \"https://irma.nps.gov/STATS/SSRSReports/National%20Reports/Annual%20Visitation%20By%20Park%20(1979%20-%20Last%20Calendar%20Year)\"\n",
    "attendanceFilePath = \"data/finalAttendance.csv\"\n",
    "print(f\"{attendanceFilePath} is {round(os.path.getsize(attendanceFilePath)/1024/1024, 2)} megabytes (MB).\\nMore info here:\\n{attendanceURL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV file into DataFrame\n",
    "attendance_df = pd.read_csv(attendanceFilePath)\n",
    "attendance_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. &nbsp;National Parks (from JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform Location Number (park code) column to all caps\n",
    "a_df[\"Location Number\"] = a_df[\"Location Number\"].str.upper()\n",
    "a_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "a_df.drop(columns = [\"Address\", \"City\", \"State\", \"Zip Code\", \"Phone Number\", \"Fax Number\", \"Location\"], inplace = True)\n",
    "a_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "a_df = a_df.rename(columns = {\"Location Number\":\"Code\", \"Location Name\":\"Name\"})\n",
    "a_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. &nbsp;National Parks (from CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new DataFrame with only desired columns\n",
    "b_df = bRaw_df[[\"UNIT_CODE\", \"UNIT_NAME\"]].copy()\n",
    "b_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "b_df = b_df.rename(columns = {\"UNIT_CODE\":\"Code\", \"UNIT_NAME\":\"Name\"})\n",
    "b_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort DataFrame by National Park name\n",
    "b_df.sort_values(by = [\"Name\"], ascending = True, inplace = True)\n",
    "b_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index in place\n",
    "b_df.reset_index(inplace = True, drop = True)\n",
    "b_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *Merge A and B DataFrames to create one list of National Parks DataFrame*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge DataFrames\n",
    "natParksRaw_df = pd.merge(b_df, a_df, how = \"left\", left_on = \"Code\", right_on = \"Code\")\n",
    "natParksRaw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "natParksRaw_df.drop(columns = [\"Name_y\"], inplace = True)\n",
    "natParksRaw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "natParksRaw_df = natParksRaw_df.rename(columns = {\"Name_x\":\"Name\"})\n",
    "natParksRaw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame size\n",
    "natParksRaw_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of unique values in Code column\n",
    "a = len(pd.unique(natParksRaw_df[\"Code\"]))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify rows with duplicate value in Code column\n",
    "duplicates_df = natParksRaw_df[natParksRaw_df.duplicated(\"Code\")]\n",
    "duplicates_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with duplicates in Code column (acreage is totaled on first row of duplicates on natParksArea CSV)\n",
    "natParksRaw_df = natParksRaw_df.drop_duplicates(subset = \"Code\", keep = \"first\")\n",
    "natParksRaw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame from rows with missing lat/lng values\n",
    "null_df = natParksRaw_df[natParksRaw_df.isnull().any(axis = 1)]\n",
    "null_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of unique values in Code column\n",
    "b = len(pd.unique(null_df[\"Code\"]))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Export DataFrame to CSV for manual lat/lng entry\n",
    "# null_df.to_csv(\"data/missingCoordinates.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV file into DataFrame\n",
    "missingCoordinates_df = pd.read_csv(\"data/missingCoordinates.csv\", encoding = \"iso-8859-1\")\n",
    "missingCoordinates_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unwanted space from strings in Longitude column\n",
    "missingCoordinates_df[\"Longitude\"] = missingCoordinates_df[\"Longitude\"].str.replace(\" \", \"\")\n",
    "missingCoordinates_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary column\n",
    "missingCoordinates_df.drop(columns = [\"Unnamed: 0\"], inplace = True)\n",
    "missingCoordinates_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Longitude column to float\n",
    "missingCoordinates_df[\"Longitude\"] = missingCoordinates_df[\"Longitude\"].astype(float)\n",
    "missingCoordinates_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types\n",
    "missingCoordinates_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *Merge National Parks and Missing Coordinates DataFrames*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge DataFrames\n",
    "np_df = natParksRaw_df.merge(missingCoordinates_df, how = \"left\", left_on = \"Code\", right_on = \"Code\")\n",
    "np_df[\"Latitude_x\"].fillna(np_df[\"Latitude_y\"], inplace = True)\n",
    "np_df[\"Longitude_x\"].fillna(np_df[\"Longitude_y\"], inplace = True)\n",
    "np_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of unique values in Code column\n",
    "c = len(pd.unique(np_df[\"Code\"]))\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "np_df.drop(columns = [\"Name_y\", \"Latitude_y\", \"Longitude_y\"], inplace = True)\n",
    "np_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "np_df = np_df.rename(columns = {\"Name_x\":\"Name\", \"Latitude_x\":\"Latitude\", \"Longitude_x\":\"Longitude\"})\n",
    "np_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame size\n",
    "np_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. &nbsp;National Parks with Size in Acres (from CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new DataFrame with only desired columns\n",
    "c_df = cRaw_df[[\"UNIT_CODE\", \"UNIT_NAME\", \"Shape__Acreage\"]].copy()\n",
    "c_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "c_df = c_df.rename(columns = {\"UNIT_CODE\":\"Code\", \"UNIT_NAME\":\"Name\", \"Shape__Acreage\":\"Area\"})\n",
    "c_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort DataFrame by National Park name\n",
    "c_df.sort_values(by = [\"Name\"], ascending = True, inplace = True)\n",
    "c_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index in place\n",
    "c_df.reset_index(inplace = True, drop = True)\n",
    "c_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of unique values in Code column\n",
    "d = len(pd.unique(c_df[\"Code\"]))\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame size\n",
    "c_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *Merge National Parks and National Parks Area DataFrames*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge DataFrames\n",
    "natParksArea_df = np_df.merge(c_df, how = \"left\", left_on = \"Code\", right_on = \"Code\")\n",
    "natParksArea_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of unique values in Code column\n",
    "e = len(pd.unique(natParksArea_df[\"Code\"]))\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "natParksArea_df.drop(columns = [\"Name_y\"], inplace = True)\n",
    "natParksArea_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "natParksArea_df = natParksArea_df.rename(columns = {\"Name_x\":\"Name\"})\n",
    "natParksArea_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index in place\n",
    "natParksArea_df.reset_index(inplace = True, drop = True)\n",
    "natParksArea_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame size\n",
    "natParksArea_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame to look for rows with NaN values\n",
    "nullArea_df = natParksArea_df[natParksArea_df.isnull().any(axis = 1)]\n",
    "nullArea_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append missing acreage area to ALKA\n",
    "natParksArea_df[\"Area\"][5] = 424.242424"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. &nbsp;Points of Interest (from CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new DataFrame with only desired columns\n",
    "allPoints_df = rawPoints_df[[\"MAPLABEL\", \"POITYPE\", \"Y\", \"X\"]].copy()\n",
    "allPoints_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "allPoints_df = allPoints_df.rename(columns = {\"MAPLABEL\":\"Name\", \"POITYPE\":\"Type\", \"Y\":\"Latitude\", \"X\":\"Longitude\"})\n",
    "allPoints_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform blank string values to NaN values\n",
    "allPoints_df[\"Name\"].replace(\" \", np.nan, inplace = True)\n",
    "allPoints_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows containing NaN values\n",
    "allPoints_df.dropna(subset = [\"Name\"], inplace = True)\n",
    "allPoints_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index in place\n",
    "allPoints_df.reset_index(inplace = True, drop = True)\n",
    "allPoints_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # List all points of interest types\n",
    "# allPoints_df[\"Type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types\n",
    "allPoints_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parking Lots DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare boolean variable to filter by parking lots\n",
    "parkingLots = allPoints_df[\"Type\"] == \"Parking Lot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new DataFrame filtered on parking lots\n",
    "parking_df = allPoints_df[parkingLots]\n",
    "parking_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for SQL compatibility\n",
    "parking_df = parking_df.rename(columns = {\"Name\":\"name\", \"Type\":\"type\", \"Latitude\":\"latitude\", \"Longitude\":\"longitude\"})\n",
    "parking_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index in place\n",
    "parking_df.reset_index(inplace = True, drop = True)\n",
    "parking_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Points of Interest: &nbsp;Activities & Sports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new DataFrame filtered on desired type values\n",
    "sportsActivities_df = allPoints_df[(allPoints_df.Type == \"Athletic Field\") |\n",
    "                                   (allPoints_df.Type == \"Ballfield\") |\n",
    "                                   (allPoints_df.Type == \"Baseball/Softball\") |\n",
    "                                   (allPoints_df.Type == \"Basketball\") |\n",
    "                                   (allPoints_df.Type == \"Beach\") |\n",
    "                                   (allPoints_df.Type == \"Bicycle Trail\") |\n",
    "                                   (allPoints_df.Type == \"Cross-Country Ski Trail\") |\n",
    "                                   (allPoints_df.Type == \"Downhill Ski Trail\") |\n",
    "                                   (allPoints_df.Type == \"Fish Cleaning\") |\n",
    "                                   (allPoints_df.Type == \"Fishing\") |\n",
    "                                   (allPoints_df.Type == \"Four-wheel Drive Trail\") |\n",
    "                                   (allPoints_df.Type == \"Golf Course\") |\n",
    "                                   (allPoints_df.Type == \"Horseback Riding\") |\n",
    "                                   (allPoints_df.Type == \"Horseback Riding/Stable\") |\n",
    "                                   (allPoints_df.Type == \"Ice Rink\") |\n",
    "                                   (allPoints_df.Type == \"Motorized Trail\") |\n",
    "                                   (allPoints_df.Type == \"Non-Motorized Trail\") |\n",
    "                                   (allPoints_df.Type == \"Playground\") |\n",
    "                                   (allPoints_df.Type == \"Roller Skating\") |\n",
    "                                   (allPoints_df.Type == \"Scuba Diving\") |\n",
    "                                   (allPoints_df.Type == \"Sledding\") |\n",
    "                                   (allPoints_df.Type == \"Soccer\") |\n",
    "                                   (allPoints_df.Type == \"Stable\") |\n",
    "                                   (allPoints_df.Type == \"Swim Club\") |\n",
    "                                   (allPoints_df.Type == \"Swimming Area\") |\n",
    "                                   (allPoints_df.Type == \"Tennis\") |\n",
    "                                   (allPoints_df.Type == \"Tennis Court\") |\n",
    "                                   (allPoints_df.Type == \"Trail\") |\n",
    "                                   (allPoints_df.Type == \"Trail Marker\") |\n",
    "                                   (allPoints_df.Type == \"Trail Register\") |\n",
    "                                   (allPoints_df.Type == \"Trail Sign\") |\n",
    "                                   (allPoints_df.Type == \"Trailhead\") |\n",
    "                                   (allPoints_df.Type == \"Volleyball\")]\n",
    "sportsActivities_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for SQL compatibility\n",
    "sportsActivities_df = sportsActivities_df.rename(columns = {\"Name\":\"name\", \"Type\":\"type\", \"Latitude\":\"latitude\",\n",
    "                                                            \"Longitude\":\"longitude\"})\n",
    "sportsActivities_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index in place\n",
    "sportsActivities_df.reset_index(inplace = True, drop = True)\n",
    "sportsActivities_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Points of Interest: &nbsp;Amenities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new DataFrame filtered on desired type values\n",
    "amenities_df = allPoints_df[(allPoints_df.Type == \"ATM\") |\n",
    "                            (allPoints_df.Type == \"Automated Fee Machine\") |\n",
    "                            (allPoints_df.Type == \"Brochure Box\") |\n",
    "                            (allPoints_df.Type == \"Directional Sign\") |\n",
    "                            (allPoints_df.Type == \"Fee Booth\") |\n",
    "                            (allPoints_df.Type == \"Food Concession\") |\n",
    "                            (allPoints_df.Type == \"Food Service\") |\n",
    "                            (allPoints_df.Type == \"Gas Station\") |\n",
    "                            (allPoints_df.Type == \"Gift Shop\") |\n",
    "                            (allPoints_df.Type == \"InfoKiosk\") |\n",
    "                            (allPoints_df.Type == \"Information\") |\n",
    "                            (allPoints_df.Type == \"Information Board\") |\n",
    "                            (allPoints_df.Type == \"Information Map\") |\n",
    "                            (allPoints_df.Type == \"NPS Office\") |\n",
    "                            (allPoints_df.Type == \"Office\") |\n",
    "                            (allPoints_df.Type == \"Park Office\") |\n",
    "                            (allPoints_df.Type == \"Post Office\") |\n",
    "                            (allPoints_df.Type == \"Regulatory Sign\") |\n",
    "                            (allPoints_df.Type == \"Restroom\") |\n",
    "                            (allPoints_df.Type == \"Retail Building\") |\n",
    "                            (allPoints_df.Type == \"Retail Concession\") |\n",
    "                            (allPoints_df.Type == \"Store\") |\n",
    "                            (allPoints_df.Type == \"Telephone\") |\n",
    "                            (allPoints_df.Type == \"Visitor Center\") |\n",
    "                            (allPoints_df.Type == \"Wheelchair Accessible\")]\n",
    "amenities_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for SQL compatibility\n",
    "amenities_df = amenities_df.rename(columns = {\"Name\":\"name\", \"Type\":\"type\", \"Latitude\":\"latitude\",\n",
    "                                              \"Longitude\":\"longitude\"})\n",
    "amenities_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index in place\n",
    "amenities_df.reset_index(inplace = True, drop = True)\n",
    "amenities_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Points of Interest: &nbsp;Attractions & Geographic Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new DataFrame filtered on desired type values\n",
    "attractions_df = allPoints_df[(allPoints_df.Type == \"Amphitheater\") |\n",
    "                              (allPoints_df.Type == \"Arch\") |\n",
    "                              (allPoints_df.Type == \"Basin\") |\n",
    "                              (allPoints_df.Type == \"Battlefield\") |\n",
    "                              (allPoints_df.Type == \"Battlefield Marker\") |\n",
    "                              (allPoints_df.Type == \"Cable Car\") |\n",
    "                              (allPoints_df.Type == \"Cave Entrance\") |\n",
    "                              (allPoints_df.Type == \"Cinema\") |\n",
    "                              (allPoints_df.Type == \"Cliff\") |\n",
    "                              (allPoints_df.Type == \"Cultural Center\") |\n",
    "                              (allPoints_df.Type == \"Cultural Landscape\") |\n",
    "                              (allPoints_df.Type == \"Dam\") |\n",
    "                              (allPoints_df.Type == \"Dune\") |\n",
    "                              (allPoints_df.Type == \"Education Center\") |\n",
    "                              (allPoints_df.Type == \"Forest\") |\n",
    "                              (allPoints_df.Type == \"Fountain\") |\n",
    "                              (allPoints_df.Type == \"Garden\") |\n",
    "                              (allPoints_df.Type == \"Gazebo\") |\n",
    "                              (allPoints_df.Type == \"Geyser\") |\n",
    "                              (allPoints_df.Type == \"Grove\") |\n",
    "                              (allPoints_df.Type == \"Island\") |\n",
    "                              (allPoints_df.Type == \"Lava\") |\n",
    "                              (allPoints_df.Type == \"Library\") |\n",
    "                              (allPoints_df.Type == \"Lighthouse\") |\n",
    "                              (allPoints_df.Type == \"Memorial\") |\n",
    "                              (allPoints_df.Type == \"Monument\") |\n",
    "                              (allPoints_df.Type == \"Monument or Memorial\") |\n",
    "                              (allPoints_df.Type == \"Museum\") |\n",
    "                              (allPoints_df.Type == \"Natural Feature\") |\n",
    "                              (allPoints_df.Type == \"Overlook\") |\n",
    "                              (allPoints_df.Type == \"Overlook or Viewpoint\") |\n",
    "                              (allPoints_df.Type == \"Point of Interest\") |\n",
    "                              (allPoints_df.Type == \"Quarry (Mine)\") |\n",
    "                              (allPoints_df.Type == \"Rapids\") |\n",
    "                              (allPoints_df.Type == \"Ridge\") |\n",
    "                              (allPoints_df.Type == \"Rock Formation\") |\n",
    "                              (allPoints_df.Type == \"Sculpture\") |\n",
    "                              (allPoints_df.Type == \"Site of Interest\") |\n",
    "                              (allPoints_df.Type == \"Totem Pole\") |\n",
    "                              (allPoints_df.Type == \"Tour Stop\") |\n",
    "                              (allPoints_df.Type == \"Valley\") |\n",
    "                              (allPoints_df.Type == \"Viewpoint\") |\n",
    "                              (allPoints_df.Type == \"Volcano\") |\n",
    "                              (allPoints_df.Type == \"Volcano (Crater)\") |\n",
    "                              (allPoints_df.Type == \"Waterfall\") |\n",
    "                              (allPoints_df.Type == \"Wildlife Viewing\") |\n",
    "                              (allPoints_df.Type == \"Windmill\")]\n",
    "attractions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for SQL compatibility\n",
    "attractions_df = attractions_df.rename(columns = {\"Name\":\"name\", \"Type\":\"type\", \"Latitude\":\"latitude\",\n",
    "                                                  \"Longitude\":\"longitude\"})\n",
    "attractions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index in place\n",
    "attractions_df.reset_index(inplace = True, drop = True)\n",
    "attractions_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Points of Interest: &nbsp;Boating & Watercraft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new DataFrame filtered on desired type values\n",
    "boating_df = allPoints_df[(allPoints_df.Type == \"Bay\") |\n",
    "                          (allPoints_df.Type == \"Boat Dock\") |\n",
    "                          (allPoints_df.Type == \"Boat Launch\") |\n",
    "                          (allPoints_df.Type == \"Boat Storage\") |\n",
    "                          (allPoints_df.Type == \"Boathouse\") |\n",
    "                          (allPoints_df.Type == \"Buoy\") |\n",
    "                          (allPoints_df.Type == \"Canal\") |\n",
    "                          (allPoints_df.Type == \"Canal Lock\") |\n",
    "                          (allPoints_df.Type == \"Canoe/Kayak Access\") |\n",
    "                          (allPoints_df.Type == \"Canoe / Kayak Access\") |\n",
    "                          (allPoints_df.Type == \"Canoe/Small Boat Access\") |\n",
    "                          (allPoints_df.Type == \"Gas Station - Boat only\") |\n",
    "                          (allPoints_df.Type == \"Harbor\") |\n",
    "                          (allPoints_df.Type == \"Lake\") |\n",
    "                          (allPoints_df.Type == \"Marina\") |\n",
    "                          (allPoints_df.Type == \"Mooring\") |\n",
    "                          (allPoints_df.Type == \"Reservoir\") |\n",
    "                          (allPoints_df.Type == \"Sailing\") |\n",
    "                          (allPoints_df.Type == \"Windsurfing Area\") |\n",
    "                          (allPoints_df.Type == \"Zebra Mussel Decontamination Station\")]\n",
    "boating_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for SQL compatibility\n",
    "boating_df = boating_df.rename(columns = {\"Name\":\"name\", \"Type\":\"type\", \"Latitude\":\"latitude\",\n",
    "                                          \"Longitude\":\"longitude\"})\n",
    "boating_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index in place\n",
    "boating_df.reset_index(inplace = True, drop = True)\n",
    "boating_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Points of Interest: &nbsp;Camping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new DataFrame filtered on desired type values\n",
    "camping_df = allPoints_df[(allPoints_df.Type == \"Campfire Ring\") |\n",
    "                          (allPoints_df.Type == \"Campground\") |\n",
    "                          (allPoints_df.Type == \"Campground, Trailer\") |\n",
    "                          (allPoints_df.Type == \"Campsite\") |\n",
    "                          (allPoints_df.Type == \"Campsite, Primitive\") |\n",
    "                          (allPoints_df.Type == \"Dormitory\") |\n",
    "                          (allPoints_df.Type == \"Dump Station\") |\n",
    "                          (allPoints_df.Type == \"Dumpster\") |\n",
    "                          (allPoints_df.Type == \"Firewood\") |\n",
    "                          (allPoints_df.Type == \"Grill\") |\n",
    "                          (allPoints_df.Type == \"Laundry\") |\n",
    "                          (allPoints_df.Type == \"Litter Receptacle\") |\n",
    "                          (allPoints_df.Type == \"Picnic Area\") |\n",
    "                          (allPoints_df.Type == \"Picnic Table\") |\n",
    "                          (allPoints_df.Type == \"Potable Water\") |\n",
    "                          (allPoints_df.Type == \"Primitive Camping\") |\n",
    "                          (allPoints_df.Type == \"Recycling\") |\n",
    "                          (allPoints_df.Type == \"Restroom\") |\n",
    "                          (allPoints_df.Type == \"RV Campground\") |\n",
    "                          (allPoints_df.Type == \"Showers\")]\n",
    "camping_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for SQL compatibility\n",
    "camping_df = camping_df.rename(columns = {\"Name\":\"name\", \"Type\":\"type\", \"Latitude\":\"latitude\",\n",
    "                                          \"Longitude\":\"longitude\"})\n",
    "camping_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index in place\n",
    "camping_df.reset_index(inplace = True, drop = True)\n",
    "camping_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Points of Interest: &nbsp;Emergency Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new DataFrame filtered on desired type values\n",
    "emergency_df = allPoints_df[(allPoints_df.Type == \"Clinic\") |\n",
    "                            (allPoints_df.Type == \"Fire Station\") |\n",
    "                            (allPoints_df.Type == \"First Aid Station\") |\n",
    "                            (allPoints_df.Type == \"Hospital\") |\n",
    "                            (allPoints_df.Type == \"Patrol Cabin\") |\n",
    "                            (allPoints_df.Type == \"Police\") |\n",
    "                            (allPoints_df.Type == \"Ranger Station\") |\n",
    "                            (allPoints_df.Type == \"Shelter\") |\n",
    "                            (allPoints_df.Type == \"Telephone\") |\n",
    "                            (allPoints_df.Type == \"Weather Shelter\")]\n",
    "emergency_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for SQL compatibility\n",
    "emergency_df = emergency_df.rename(columns = {\"Name\":\"name\", \"Type\":\"type\", \"Latitude\":\"latitude\",\n",
    "                                              \"Longitude\":\"longitude\"})\n",
    "emergency_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index in place\n",
    "emergency_df.reset_index(inplace = True, drop = True)\n",
    "emergency_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Points of Interest: &nbsp;Historic Sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new DataFrame filtered on desired type values\n",
    "historic_df = allPoints_df[(allPoints_df.Type == \"Battlefield\") |\n",
    "                           (allPoints_df.Type == \"Battlefield Marker\") |\n",
    "                           (allPoints_df.Type == \"Cannon\") |\n",
    "                           (allPoints_df.Type == \"Cemetery / Graveyard\") |\n",
    "                           (allPoints_df.Type == \"Grave\") |\n",
    "                           (allPoints_df.Type == \"Historic Building\") |\n",
    "                           (allPoints_df.Type == \"Historic Cabin\") |\n",
    "                           (allPoints_df.Type == \"Historic District\") |\n",
    "                           (allPoints_df.Type == \"Historic Marker\") |\n",
    "                           (allPoints_df.Type == \"Historic Mine\") |\n",
    "                           (allPoints_df.Type == \"Historic Ruins\") |\n",
    "                           (allPoints_df.Type == \"Historic Site\") |\n",
    "                           (allPoints_df.Type == \"Library\") |\n",
    "                           (allPoints_df.Type == \"Museum\") |\n",
    "                           (allPoints_df.Type == \"Totem Pole\")]\n",
    "historic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for SQL compatibility\n",
    "historic_df = historic_df.rename(columns = {\"Name\":\"name\", \"Type\":\"type\", \"Latitude\":\"latitude\",\n",
    "                                            \"Longitude\":\"longitude\"})\n",
    "historic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index in place\n",
    "historic_df.reset_index(inplace = True, drop = True)\n",
    "historic_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Points of Interest: &nbsp;Parking & Transportation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new DataFrame filtered on desired type values\n",
    "parkingTransportation_df = allPoints_df[(allPoints_df.Type == \"Bus or Shuttle Stop\") |\n",
    "                                        (allPoints_df.Type == \"Bus Stop / Shuttle Stop\") |\n",
    "                                        (allPoints_df.Type == \"Electric Vehicle Parking\") |\n",
    "                                        (allPoints_df.Type == \"Entrance / Exit\") |\n",
    "                                        (allPoints_df.Type == \"Entrance Station\") |\n",
    "                                        (allPoints_df.Type == \"Entrance/Exit\") |\n",
    "                                        (allPoints_df.Type == \"Ferry Terminal\") |\n",
    "                                        (allPoints_df.Type == \"Garage\") |\n",
    "                                        (allPoints_df.Type == \"Gas Station\") |\n",
    "                                        (allPoints_df.Type == \"Gate\") |\n",
    "                                        (allPoints_df.Type == \"Gateway Sign\") |\n",
    "                                        (allPoints_df.Type == \"Metro Station\") |\n",
    "                                        (allPoints_df.Type == \"Parking Lot\") |\n",
    "                                        (allPoints_df.Type == \"Parking, Disabled Only\") |\n",
    "                                        (allPoints_df.Type == \"Road\") |\n",
    "                                        (allPoints_df.Type == \"Roadside Pullout\") |\n",
    "                                        (allPoints_df.Type == \"Train Station\")]\n",
    "parkingTransportation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for SQL compatibility\n",
    "parkingTransportation_df = parkingTransportation_df.rename(columns = {\"Name\":\"name\", \"Type\":\"type\", \"Latitude\":\"latitude\",\n",
    "                                                                      \"Longitude\":\"longitude\"})\n",
    "parkingTransportation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index in place\n",
    "parkingTransportation_df.reset_index(inplace = True, drop = True)\n",
    "parkingTransportation_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. &nbsp;Attendance/Visitors (Recreation Visits; from CSV)\n",
    "- By Park by Year\n",
    "- \"Presidents' Park\" did not have its own code; combined these attendance values with White House attendance numbers.\n",
    "- \"Klondike Gold Rush - Seattle\" technically falls under Klondike Gold Rush - Alaska and does not have its own code; eliminated this record altogether (average annual attendance is 66,907)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename column\n",
    "attendance_df = attendance_df.rename(columns = {\"Park Name\":\"Name\"})\n",
    "attendance_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of unique values in Code column\n",
    "f = len(pd.unique(attendance_df[\"Code\"]))\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types\n",
    "attendance_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform blank string values to NaN values\n",
    "attendance_df[\"2011\"].replace(\" \", np.nan, inplace = True)\n",
    "attendance_df[\"2012\"].replace(\" \", np.nan, inplace = True)\n",
    "attendance_df[\"2013\"].replace(\" \", np.nan, inplace = True)\n",
    "attendance_df[\"2014\"].replace(\" \", np.nan, inplace = True)\n",
    "attendance_df[\"2015\"].replace(\" \", np.nan, inplace = True)\n",
    "attendance_df[\"2016\"].replace(\" \", np.nan, inplace = True)\n",
    "attendance_df[\"2017\"].replace(\" \", np.nan, inplace = True)\n",
    "attendance_df[\"2018\"].replace(\" \", np.nan, inplace = True)\n",
    "attendance_df[\"2019\"].replace(\" \", np.nan, inplace = True)\n",
    "attendance_df[\"2020\"].replace(\" \", np.nan, inplace = True)\n",
    "attendance_df[\"Average\"].replace(\" \", np.nan, inplace = True)\n",
    "attendance_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove commas from string values in yearly attendance columns\n",
    "attendance_df[\"2011\"] = attendance_df[\"2011\"].str.replace(\",\", \"\")\n",
    "attendance_df[\"2012\"] = attendance_df[\"2012\"].str.replace(\",\", \"\")\n",
    "attendance_df[\"2013\"] = attendance_df[\"2013\"].str.replace(\",\", \"\")\n",
    "attendance_df[\"2014\"] = attendance_df[\"2014\"].str.replace(\",\", \"\")\n",
    "attendance_df[\"2015\"] = attendance_df[\"2015\"].str.replace(\",\", \"\")\n",
    "attendance_df[\"2016\"] = attendance_df[\"2016\"].str.replace(\",\", \"\")\n",
    "attendance_df[\"2017\"] = attendance_df[\"2017\"].str.replace(\",\", \"\")\n",
    "attendance_df[\"2018\"] = attendance_df[\"2018\"].str.replace(\",\", \"\")\n",
    "attendance_df[\"2019\"] = attendance_df[\"2019\"].str.replace(\",\", \"\")\n",
    "attendance_df[\"2020\"] = attendance_df[\"2020\"].str.replace(\",\", \"\")\n",
    "attendance_df[\"Average\"] = attendance_df[\"Average\"].str.replace(\",\", \"\")\n",
    "attendance_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform NaN values to \"0\"\n",
    "attendance_df[\"2011\"] = attendance_df[\"2011\"].fillna(0)\n",
    "attendance_df[\"2012\"] = attendance_df[\"2012\"].fillna(0)\n",
    "attendance_df[\"2013\"] = attendance_df[\"2013\"].fillna(0)\n",
    "attendance_df[\"2014\"] = attendance_df[\"2014\"].fillna(0)\n",
    "attendance_df[\"2015\"] = attendance_df[\"2015\"].fillna(0)\n",
    "attendance_df[\"2016\"] = attendance_df[\"2016\"].fillna(0)\n",
    "attendance_df[\"2017\"] = attendance_df[\"2017\"].fillna(0)\n",
    "attendance_df[\"2018\"] = attendance_df[\"2018\"].fillna(0)\n",
    "attendance_df[\"2019\"] = attendance_df[\"2019\"].fillna(0)\n",
    "attendance_df[\"2020\"] = attendance_df[\"2020\"].fillna(0)\n",
    "attendance_df[\"Average\"] = attendance_df[\"Average\"].fillna(0)\n",
    "attendance_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform values to integers\n",
    "attendance_df[\"2011\"] = attendance_df[\"2011\"].astype(int)\n",
    "attendance_df[\"2012\"] = attendance_df[\"2012\"].astype(int)\n",
    "attendance_df[\"2013\"] = attendance_df[\"2013\"].astype(int)\n",
    "attendance_df[\"2014\"] = attendance_df[\"2014\"].astype(int)\n",
    "attendance_df[\"2015\"] = attendance_df[\"2015\"].astype(int)\n",
    "attendance_df[\"2016\"] = attendance_df[\"2016\"].astype(int)\n",
    "attendance_df[\"2017\"] = attendance_df[\"2017\"].astype(int)\n",
    "attendance_df[\"2018\"] = attendance_df[\"2018\"].astype(int)\n",
    "attendance_df[\"2019\"] = attendance_df[\"2019\"].astype(int)\n",
    "attendance_df[\"2020\"] = attendance_df[\"2020\"].astype(int)\n",
    "attendance_df[\"Average\"] = attendance_df[\"Average\"].astype(int)\n",
    "attendance_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types\n",
    "attendance_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame size\n",
    "attendance_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *Merge National Parks and Attendance DataFrames and create one comprehensive natParks DataFrame*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge DataFrames\n",
    "natParks_df = natParksArea_df.merge(attendance_df, how = \"left\", left_on = \"Code\", right_on = \"Code\")\n",
    "natParks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "natParks_df.drop(columns = [\"Name_y\"], inplace = True)\n",
    "natParks_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for compatibility with SQL\n",
    "natParks_df = natParks_df.rename(columns = {\"Code\":\"code\", \"Name_x\":\"name\", \"Latitude\":\"latitude\", \"Longitude\":\"longitude\",\n",
    "                                            \"Area\":\"acres\", \"2011\":\"att_2011\", \"2012\":\"att_2012\", \"2013\":\"att_2013\",\n",
    "                                            \"2014\":\"att_2014\", \"2015\":\"att_2015\", \"2016\":\"att_2016\", \"2017\":\"att_2017\",\n",
    "                                            \"2018\":\"att_2018\", \"2019\":\"att_2019\", \"2020\":\"att_2020\", \"Average\":\"att_average\"})\n",
    "natParks_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types\n",
    "natParks_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform NaN values to \"0\"\n",
    "natParks_df[\"att_2011\"] = natParks_df[\"att_2011\"].fillna(0)\n",
    "natParks_df[\"att_2012\"] = natParks_df[\"att_2012\"].fillna(0)\n",
    "natParks_df[\"att_2013\"] = natParks_df[\"att_2013\"].fillna(0)\n",
    "natParks_df[\"att_2014\"] = natParks_df[\"att_2014\"].fillna(0)\n",
    "natParks_df[\"att_2015\"] = natParks_df[\"att_2015\"].fillna(0)\n",
    "natParks_df[\"att_2016\"] = natParks_df[\"att_2016\"].fillna(0)\n",
    "natParks_df[\"att_2017\"] = natParks_df[\"att_2017\"].fillna(0)\n",
    "natParks_df[\"att_2018\"] = natParks_df[\"att_2018\"].fillna(0)\n",
    "natParks_df[\"att_2019\"] = natParks_df[\"att_2019\"].fillna(0)\n",
    "natParks_df[\"att_2020\"] = natParks_df[\"att_2020\"].fillna(0)\n",
    "natParks_df[\"att_average\"] = natParks_df[\"att_average\"].fillna(0)\n",
    "natParks_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform values to integers\n",
    "natParks_df[\"att_2011\"] = natParks_df[\"att_2011\"].astype(int)\n",
    "natParks_df[\"att_2012\"] = natParks_df[\"att_2012\"].astype(int)\n",
    "natParks_df[\"att_2013\"] = natParks_df[\"att_2013\"].astype(int)\n",
    "natParks_df[\"att_2014\"] = natParks_df[\"att_2014\"].astype(int)\n",
    "natParks_df[\"att_2015\"] = natParks_df[\"att_2015\"].astype(int)\n",
    "natParks_df[\"att_2016\"] = natParks_df[\"att_2016\"].astype(int)\n",
    "natParks_df[\"att_2017\"] = natParks_df[\"att_2017\"].astype(int)\n",
    "natParks_df[\"att_2018\"] = natParks_df[\"att_2018\"].astype(int)\n",
    "natParks_df[\"att_2019\"] = natParks_df[\"att_2019\"].astype(int)\n",
    "natParks_df[\"att_2020\"] = natParks_df[\"att_2020\"].astype(int)\n",
    "natParks_df[\"att_average\"] = natParks_df[\"att_average\"].astype(int)\n",
    "natParks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types\n",
    "natParks_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export DataFrames to CSV files\n",
    "sportsActivities_df.to_csv(\"resources/sportsActivitiesFinal.csv\")\n",
    "amenities_df.to_csv(\"resources/amenitiesFinal.csv\")\n",
    "attractions_df.to_csv(\"resources/attractionsFinal.csv\")\n",
    "boating_df.to_csv(\"resources/boatingFinal.csv\")\n",
    "camping_df.to_csv(\"resources/campingFinal.csv\")\n",
    "emergency_df.to_csv(\"resources/emergencyFinal.csv\")\n",
    "historic_df.to_csv(\"resources/historicFinal.csv\")\n",
    "natParks_df.to_csv(\"resources/natParksFinal.csv\")\n",
    "parking_df.to_csv(\"resources/parkingFinal.csv\")\n",
    "parkingTransportation_df.to_csv(\"resources/parkingTransportationFinal.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### postgreSQL Method (functioning correctly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an engine that can talk to the database\n",
    "engine = create_engine(f'postgresql://postgres:cnm302@localhost:5432/natParks')\n",
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for table\n",
    "engine.table_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pandas to load DataFrames into natParks database\n",
    "natParks_df.to_sql(name = \"natparks\", con = engine, if_exists = \"append\", index = False)\n",
    "sportsActivities_df.to_sql(name = \"sportsactivities\", con = engine, if_exists = \"append\", index = False)\n",
    "amenities_df.to_sql(name = \"amenities\", con = engine, if_exists = \"append\", index = False)\n",
    "attractions_df.to_sql(name = \"attractions\", con = engine, if_exists = \"append\", index = False)\n",
    "boating_df.to_sql(name = \"boating\", con = engine, if_exists = \"append\", index = False)\n",
    "camping_df.to_sql(name = \"camping\", con = engine, if_exists = \"append\", index = False)\n",
    "emergency_df.to_sql(name = \"emergency\", con = engine, if_exists = \"append\", index = False)\n",
    "historic_df.to_sql(name = \"historic\", con = engine, if_exists = \"append\", index = False)\n",
    "parking_df.to_sql(name = \"parkinglots\", con = engine, if_exists = \"append\", index = False)\n",
    "parkingTransportation_df.to_sql(name = \"parkingtransportation\", con = engine, if_exists = \"append\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code below to be used for creating SQLite Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Method 1. &nbsp;Insert Data with Classes and Constructors (10.2 Activities 1, 3, and 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sets an object to utilize the default declarative base in SQL Alchemy\n",
    "# Base = declarative_base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create classes to define our tables\n",
    "# class Parks(Base):\n",
    "#     __tablename__ = \"natparks\"\n",
    "#     id = Column(Integer, primary_key = True)\n",
    "#     code = Column(String(255))\n",
    "#     name = Column(String(255))\n",
    "#     latitude = Column(Float)\n",
    "#     longitude = Column(Float)\n",
    "#     acres = Column(Float)\n",
    "#     att_2011 = Column(Integer)\n",
    "#     att_2012 = Column(Integer)\n",
    "#     att_2013 = Column(Integer)\n",
    "#     att_2014 = Column(Integer)\n",
    "#     att_2015 = Column(Integer)\n",
    "#     att_2016 = Column(Integer)\n",
    "#     att_2017 = Column(Integer)\n",
    "#     att_2018 = Column(Integer)\n",
    "#     att_2019 = Column(Integer)\n",
    "#     att_2020 = Column(Integer)\n",
    "#     att_average = Column(Integer)\n",
    "\n",
    "# class Points(Base):\n",
    "#     __tablename__ = \"pointsinterest\"\n",
    "#     id = Column(Integer, primary_key = True)\n",
    "#     name = Column(String(255))\n",
    "#     type = Column(String(255))\n",
    "#     latitude = Column(Float)\n",
    "#     longitude = Column(Float)\n",
    "    \n",
    "# class Parking(Base):\n",
    "#     __tablename__ = \"parkinglots\"\n",
    "#     id = Column(Integer, primary_key = True)\n",
    "#     name = Column(String(255))\n",
    "#     type = Column(String(255))\n",
    "#     latitude = Column(Float)\n",
    "#     longitude = Column(Float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NEED TO FIRST CREATE NATPARKS.SQLITE REFERENCED IN CELL BELOW???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create engine to natparks.sqlite\n",
    "# engine = create_engine(\"sqlite:///resources/natparks.sqlite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create our tables in the database\n",
    "# Base.metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create our session (link) from Python to the DB\n",
    "# session = Session(bind = engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create instances of each class\n",
    "# parks = Parks(\"WHAT GOES IN HERE?\")  \"CONVERT DATAFRAMES TO DICTIONARY TO PASS IN HERE?\"\n",
    "# points = Points(\"WHAT GOES IN HERE?\")\n",
    "# lots = Parking(\"WHAT GOES IN HERE?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use the SQL Alchemy methods to run simple \"INSERT\" statements using the classes and objects\n",
    "# session.add(Parks)\n",
    "# session.add(Points)\n",
    "# session.add(Parking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Commit transaction of changes to database\n",
    "# session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Method 2. &nbsp;Insert Data with Pandas and SQLAlchemy ORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Insert Data with Pandas and SQLAlchemy ORM\n",
    "# Session = sessionmaker(bind = dest_db_con)\n",
    "# session = Session()\n",
    "# session.bulk_insert_mappings(natParks_df, df.to_dict(orient = \"records\"))\n",
    "# session.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
